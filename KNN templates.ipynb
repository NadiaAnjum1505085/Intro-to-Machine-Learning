{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category features\n",
    "continuous_features  = ['age', 'chol', 'oldpeak', 'thalch', 'trestbps']\n",
    "categorical_features = ['ca', 'cp', 'restecg', 'slope', 'thal', 'sex', 'fbs', 'exang']\n",
    "label = ['num']\n",
    "updated_categorical_features = []\n",
    "#read training data, normalize continuous features using (X - mean) / std\n",
    "def readdata():\n",
    "    df = pd.read_csv('heart_disease_uci.csv')\n",
    "    \n",
    "    # replacing nan value with std \n",
    "    for col in continuous_features:\n",
    "        df[col] = df[col].fillna(df[col].mean())\n",
    "        \n",
    "    # normalization of continuous features\n",
    "    for col in continuous_features:\n",
    "        df[col] = (df[col] - df[col].mean()) / df[col].std()\n",
    "        \n",
    "    # replacing nan value with mode \n",
    "    for col in categorical_features:\n",
    "        mode_val = df[col].mode()[0]\n",
    "        df.loc[df[col].isna(), col] = mode_val\n",
    "    df[categorical_features] = df[categorical_features].astype(\"category\")\n",
    "    \n",
    "    # replacing nan value with mode \n",
    "    for col in label:\n",
    "        mode_val = df[col].mode()[0]\n",
    "        df.loc[df[col].isna(), col] = mode_val\n",
    "        \n",
    "    # replacing 0 with negative, other values with positive\n",
    "    df['num'] = df['num'].apply(lambda x: \"positive\" if x > 0 else \"negative\")\n",
    "    \n",
    "    # One-hot encode categorical features\n",
    "    df = pd.get_dummies(df, columns=categorical_features, prefix=categorical_features, drop_first=True)\n",
    "    for col in df.columns:\n",
    "        if col not in continuous_features and col != 'num' and col != 'id' and col != 'dataset':\n",
    "            updated_categorical_features.append(col)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## KNN CLASSIFIER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate data into training, validation, and testing sets\n",
    "def dataDivision():\n",
    "    new_df = readdata()\n",
    "    shuffled_df = new_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    label_col = 'num'\n",
    "    n = len(shuffled_df)\n",
    "    \n",
    "    # separating data for test and training\n",
    "    train_length = int(0.6 * n)\n",
    "    validation_length = int(0.2 * n)\n",
    "    train_df = shuffled_df.iloc[:train_length]\n",
    "    validation_df = shuffled_df.iloc[train_length: train_length + validation_length]\n",
    "    test_df = shuffled_df.iloc[train_length + validation_length:]\n",
    "    \n",
    "    train_df_mod = train_df.drop(columns=['id','dataset'])\n",
    "    validation_df_mod = validation_df.drop(columns=['id','dataset'])\n",
    "    test_df_mod = test_df.drop(columns=['id','dataset'])\n",
    "    \n",
    "    #print(\"Columns in DataFrame:\", train_df_mod.columns, validation_df_mod.columns)\n",
    "    return train_df_mod, validation_df_mod, test_df_mod\n",
    "train_df, validation_df, test_df = dataDivision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the L2 distance between the current row and a neighbor\n",
    "def distanceCalculator(x1, x2):\n",
    "    distance =  np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "    return distance\n",
    "\n",
    "# get the K closest neighbors\n",
    "def getClosestNeighbours(train_df, validation_row, k):\n",
    "    distances = []\n",
    "    neighbours = []\n",
    "    x_train_df = train_df.drop(columns=['num']).values.astype(float)\n",
    "    y_train_df = train_df['num']\n",
    "    x_validation_row = validation_row.drop(labels=['num']).values.astype(float)\n",
    "    \n",
    "    for i in range(len(x_train_df)):\n",
    "        dst = distanceCalculator(x_validation_row, x_train_df[i])\n",
    "        distances.append((dst, y_train_df[i]))\n",
    "    distances.sort(key = lambda x:x[0])\n",
    "    for (dst, label) in distances[:k]:\n",
    "        neighbours.append(label)\n",
    "    #print(neighbours)\n",
    "    return neighbours\n",
    "        \n",
    "# knn classifier\n",
    "def knnClassify(train_df, validation_df, k):\n",
    "    neighbours = getClosestNeighbours(train_df, validation_df, k)\n",
    "    \n",
    "    class0 = neighbours.count(\"negative\")\n",
    "    class1 = neighbours.count(\"positive\")\n",
    "    \n",
    "    if class0 > class1:\n",
    "        prediction = \"negative\"\n",
    "    else:\n",
    "        prediction = \"positive\"\n",
    "    \n",
    "    return prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printConfusionMatrix(tp, fp, tn, fn):\n",
    "    print(\"\\n%15sActual\" % \"\")\n",
    "    print(\"%6s %7s %7s\" % (\"\", \"1\", \"0\"))\n",
    "    print(\"P%6s +--------+--------+\" % \"\")\n",
    "    print(\"r%6s | %-6s | %-6s |\" % (\"1\", 'TP='+str(tp), 'FP='+str(fp)))\n",
    "    print(\"e%6s +--------+--------+\" % \"\")\n",
    "    print(\"d%6s | %-6s | %-6s |\" % (\"0\", 'FN='+str(fn), 'TN='+str(tn)))\n",
    "    print(\".%6s +--------+--------+\\n\" % \"\")\n",
    "\n",
    "def getConfusionMatrix(y_true, y_pred):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    tp = int(np.sum((y_true == \"positive\") & (y_pred == \"positive\")))\n",
    "    tn = int(np.sum((y_true == \"negative\") & (y_pred == \"negative\")))\n",
    "    fp = int(np.sum((y_true == \"negative\") & (y_pred == \"positive\")))\n",
    "    fn = int(np.sum((y_true == \"positive\") & (y_pred == \"negative\")))\n",
    "    return tp, fp, tn, fn\n",
    "\n",
    "def getAccuracy(tp, fp, tn, fn):\n",
    "    if (tp+tn+fp+fn) > 0:\n",
    "        return (tp + tn) / (tp + tn + fp + fn)\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def getPrecision(tp, fp, tn, fn):\n",
    "    if (tp + fp) > 0:\n",
    "       return tp / (tp + fp)\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def getRecall(tp, fp, tn, fn):\n",
    "    if (tp + fn) > 0:\n",
    "        return tp / (tp + fn)\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def getFScore(tp, fp, tn, fn):\n",
    "    p = getPrecision(tp, fp, tn, fn)\n",
    "    r = getRecall(tp, fp, tn, fn)\n",
    "    #print(p,r)\n",
    "    if (p + r) > 0:\n",
    "        return 2 * p * r / (p + r)\n",
    "    else:\n",
    "        return 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tuning k value on validation set\n",
    "def bestKfinding(train_df, validation_df):\n",
    "    best_k = 1\n",
    "    best_f1 = 0\n",
    "    #train_df, validation_df, test_df = dataDivision()\n",
    "    for k in range(1,6):\n",
    "    #find k that gives best performance \n",
    "        y_true = validation_df['num'].values\n",
    "        y_pred = []\n",
    "        for _,row in validation_df.iterrows():\n",
    "            pred = knnClassify(train_df, row, k)   \n",
    "            y_pred.append(pred)\n",
    "        tp, fp, tn, fn = getConfusionMatrix(y_true, y_pred)\n",
    "        f1 = getFScore(tp, fp, tn, fn)\n",
    "        #print(f1)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_k = k\n",
    "    #print(best_k)\n",
    "    return best_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best k is\n",
    "best_k = bestKfinding(train_df, validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "               Actual\n",
      "             1       0\n",
      "P       +--------+--------+\n",
      "r     1 | TP=84  | FP=22  |\n",
      "e       +--------+--------+\n",
      "d     0 | FN=14  | TN=64  |\n",
      ".       +--------+--------+\n",
      "\n",
      "Accuracy:   0.80435\n",
      "Precison:   0.79245\n",
      "Recall:     0.85714\n",
      "F-Measure:  0.82353\n",
      "Best k:     5.00000\n"
     ]
    }
   ],
   "source": [
    "# testing using the best k\n",
    "y_pred_best = []\n",
    "for _,row in test_df.iterrows():\n",
    "    pred = knnClassify(train_df, row, best_k)   \n",
    "    y_pred_best.append(pred)\n",
    "    \n",
    "# report final performance\n",
    "\n",
    "tp, fp, tn, fn = getConfusionMatrix(test_df['num'].values, y_pred_best)\n",
    "printConfusionMatrix(tp, fp, tn, fn)\n",
    "                \n",
    "print('Accuracy:  %8.5f' % getAccuracy(tp, fp, tn, fn))\n",
    "print('Precison:  %8.5f' % getPrecision(tp, fp, tn, fn))\n",
    "print('Recall:    %8.5f' % getRecall(tp, fp, tn, fn))\n",
    "print('F-Measure: %8.5f' % getFScore(tp, fp, tn, fn)) \n",
    "print('Best k:    %8.5f' % best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
